{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results in various formats from one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import datetime as dt\n",
    "import torch\n",
    "import json\n",
    "import neptune\n",
    "\n",
    "from src import constants\n",
    "from src import data\n",
    "from src import utils\n",
    "from src import predictions\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.dates import DayLocator, AutoDateLocator, ConciseDateFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "EXPERIMENTS_DIR = 'experiments'\n",
    "DEVICE = 'cpu'\n",
    "NEPTUNE_PRJ = 'indiacovidseva/covid-net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = \"0001_test\"\n",
    "checkpoint = \"latest-e100.pt\"\n",
    "\n",
    "model, cp = utils.load_model(experiment_id, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['location', 'date', 'total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'population', 'population_density', 'gdp_per_capita', 'hospital_beds_per_thousand', 'median_age']\n",
    "dates = ['date']\n",
    "df = pd.read_csv(DATA_DIR + \"/\" + cp['config']['DS']['SRC'],\n",
    "                 usecols=cols,\n",
    "                 parse_dates=dates)\n",
    "df = data.fix_anomalies_owid(df)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict from OWID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"India\"\n",
    "n_days_prediction = 200\n",
    "\n",
    "# restrict predictions if outputs != inputs\n",
    "if cp['config']['IP_FEATURES'] != cp['config']['OP_FEATURES']:\n",
    "    op_len = cp['config']['DS']['OP_SEQ_LEN']\n",
    "    print(\"WARNING: Input features and output features are different. Cannot predict more than\", op_len, \"days.\")\n",
    "    n_days_prediction = op_len\n",
    "\n",
    "IP_SEQ_LEN = cp['config']['DS']['IP_SEQ_LEN']\n",
    "OP_SEQ_LEN = cp['config']['DS']['OP_SEQ_LEN']\n",
    "pop_fct = df.loc[df.location==c, 'population'].iloc[0] / 1000\n",
    "ip_aux = torch.tensor(\n",
    "            np.array(df.loc[df.location==c, cp['config']['DS']['AUX_FEATURES']].iloc[0])[cp['config']['AUX_FEATURES']],\n",
    "            dtype=torch.float32\n",
    "        ).to(DEVICE)\n",
    "test_data = np.array(df.loc[(df.location==c) & (df.total_cases>=100), cp['config']['DS']['FEATURES']].rolling(7, center=True, min_periods=1).mean() / pop_fct, dtype=np.float32)\n",
    "\n",
    "in_data = test_data[-IP_SEQ_LEN:, cp['config']['IP_FEATURES']]\n",
    "out_data = np.ndarray(shape=(0, len(cp['config']['OP_FEATURES'])), dtype=np.float32)\n",
    "for i in range(int(n_days_prediction / OP_SEQ_LEN)):\n",
    "    ip = torch.tensor(\n",
    "        in_data,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    ip = ip.to(DEVICE)\n",
    "    pred = model.predict(\n",
    "        ip.view(1, IP_SEQ_LEN, len(cp['config']['IP_FEATURES'])),\n",
    "        ip_aux.view(1, len(cp['config']['AUX_FEATURES']))\n",
    "    ).view(OP_SEQ_LEN, len(cp['config']['OP_FEATURES']))\n",
    "    in_data = np.append(in_data[-IP_SEQ_LEN+OP_SEQ_LEN:, :], pred.cpu().numpy(), axis=0)\n",
    "    out_data = np.append(out_data, pred.cpu().numpy(), axis=0)\n",
    "\n",
    "for o in cp['config']['IP_FEATURES']:\n",
    "    orig_df = pd.DataFrame({\n",
    "        'actual': test_data[:,o] * pop_fct\n",
    "    })\n",
    "    fut_df = pd.DataFrame({\n",
    "        'predicted': out_data[:,o] * pop_fct\n",
    "    })\n",
    "    # print(fut_df['predicted'].astype('int').to_csv(sep='|', index=False))\n",
    "    orig_df = orig_df.append(fut_df, ignore_index=True, sort=False)\n",
    "    orig_df['total'] = (orig_df['actual'].fillna(0) + orig_df['predicted'].fillna(0)).cumsum()\n",
    "\n",
    "    start_date = df.loc[(df.location==c) & (df.total_cases>=100)]['date'].iloc[0]\n",
    "    orig_df['Date'] = pd.Series([start_date + dt.timedelta(days=i) for i in range(len(orig_df))])\n",
    "    ax = orig_df.plot(\n",
    "        x='Date',\n",
    "        y=['actual', 'predicted'],\n",
    "        title=c + ' ' + cp['config']['DS']['FEATURES'][o],\n",
    "        figsize=(10,6),\n",
    "        grid=True\n",
    "    )\n",
    "    mn_l = DayLocator()\n",
    "    ax.xaxis.set_minor_locator(mn_l)\n",
    "    mj_l = AutoDateLocator()\n",
    "    mj_f = ConciseDateFormatter(mj_l, show_offset=False)\n",
    "    ax.xaxis.set_major_formatter(mj_f)\n",
    "    # orig_df['total'] = orig_df['total'].astype('int')\n",
    "    # orig_df['predicted'] = orig_df['predicted'].fillna(0).astype('int')\n",
    "    # print(orig_df.tail(n_days_prediction))\n",
    "\n",
    "    # arrow\n",
    "    # peakx = 172\n",
    "    # peak = orig_df.iloc[peakx]\n",
    "    # peak_desc = peak['Date'].strftime(\"%d-%b\") + \"\\n\" + str(int(peak['predicted']))\n",
    "    # _ = ax.annotate(\n",
    "    #     peak_desc, \n",
    "    #     xy=(peak['Date'] - dt.timedelta(days=1), peak['predicted']),\n",
    "    #     xytext=(peak['Date'] - dt.timedelta(days=45), peak['predicted'] * .9),\n",
    "    #     arrowprops={},\n",
    "    #     bbox={'facecolor':'white'}\n",
    "    # )\n",
    "\n",
    "    # _ = ax.axvline(x=peak['Date'], linewidth=1, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statewise predictions (covid19india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = data.get_statewise_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy state data: fruit country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy data for testing\n",
    "# SET 1 - 10 states\n",
    "# STT_INFO = {\n",
    "#     'A': {\"name\": \"Apple\", \"popn\": 10000000},\n",
    "#     'B': {\"name\": \"Berry\", \"popn\": 10000000},\n",
    "#     'C': {\"name\": \"Cherry\", \"popn\": 10000000},\n",
    "#     'D': {\"name\": \"Dates\", \"popn\": 10000000},\n",
    "#     'E': {\"name\": \"Elderberry\", \"popn\": 10000000},\n",
    "#     'F': {\"name\": \"Fig\", \"popn\": 10000000},\n",
    "#     'G': {\"name\": \"Grape\", \"popn\": 10000000},\n",
    "#     'H': {\"name\": \"Honeysuckle\", \"popn\": 10000000},\n",
    "#     'I': {\"name\": \"Icaco\", \"popn\": 10000000},\n",
    "#     'J': {\"name\": \"Jujube\", \"popn\": 10000000},\n",
    "# }\n",
    "# total = 100\n",
    "# SET 2 - 1 agg state\n",
    "STT_INFO = {\n",
    "    'Z': {\"name\": \"FruitCountry1000x\", \"popn\": 10000000},\n",
    "}\n",
    "total = 1000\n",
    "\n",
    "\n",
    "r = {\n",
    "    'state': [],\n",
    "    'date': [],\n",
    "    'total': []\n",
    "}\n",
    "\n",
    "start_date = dt.datetime(day=1, month=3, year=2020)\n",
    "end_date = dt.datetime.now()\n",
    "while start_date <= end_date:\n",
    "    for s in STT_INFO:\n",
    "        r['state'].append(s)\n",
    "        r['date'].append(start_date)\n",
    "        r['total'].append(total)\n",
    "    total *= 1.03\n",
    "    start_date += dt.timedelta(days=1)\n",
    "states_df = pd.DataFrame(r)\n",
    "states_df['date'] = pd.to_datetime(states_df['date'])\n",
    "states_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 0 # 0:confirmed, 1:deaths\n",
    "n_days_prediction = 200 # number of days for prediction\n",
    "prediction_offset = 1 # how many days of actual data to skip\n",
    "\n",
    "prediction_date = (states_df.date.max().to_pydatetime() - dt.timedelta(days=prediction_offset)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "api = predictions.generate(\n",
    "    states_df,\n",
    "    constants.STT_INFO,\n",
    "    model,\n",
    "    cp,\n",
    "    feature,\n",
    "    n_days_prediction,\n",
    "    prediction_offset,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export JSON for API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.export_tracker(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export data for video player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.export_videoplayer(api,  prediction_date, 'vp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload model to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_prj = neptune.init(NEPTUNE_PRJ)\n",
    "neptune_exp = neptune_prj.get_experiments(id=cp['config']['NEPTUNE_ID'])[0]\n",
    "neptune_exp.log_artifact(EXPERIMENTS_DIR + \"/\" + experiment_id + \"/\" + checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
