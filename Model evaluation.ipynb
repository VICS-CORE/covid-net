{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate a given model and compare multiple models. Push selected models to Neptune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import torch\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.dates import DayLocator, AutoDateLocator, ConciseDateFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "ARCHS_DIR = 'archs'\n",
    "DATA_DIR = 'data'\n",
    "EXPERIMENTS_DIR = 'experiments'\n",
    "DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = '0001_test'\n",
    "checkpoint = 'latest-e10.pt'\n",
    "\n",
    "def load_model(experiment_id, checkpoint):\n",
    "    \"\"\"returns model and checkpoint data\"\"\"\n",
    "    experiment_dir = EXPERIMENTS_DIR + '/' + experiment_id\n",
    "    cp = utils.load_checkpoint(experiment_dir, checkpoint)\n",
    "    print(\"Epochs:\", cp['epoch'])\n",
    "    config = cp['config']\n",
    "    print(config)\n",
    "\n",
    "    # init Net\n",
    "    arch_mod = importlib.import_module(\".\" + config['ARCH'], ARCHS_DIR)\n",
    "    importlib.reload(arch_mod) # ensure changes are imported\n",
    "    model = arch_mod.CovidNet(ip_seq_len=config['DS']['IP_SEQ_LEN'], op_seq_len=config['DS']['OP_SEQ_LEN'], hidden_size=config['HIDDEN_SIZE'], num_layers=config['NUM_LAYERS'])\n",
    "    model = model.to(DEVICE)\n",
    "    print (\"Model initialised\")\n",
    "    \n",
    "    model.load_state_dict(cp['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, cp\n",
    "\n",
    "model, cp = load_model(experiment_id, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['location', 'date', 'total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'population']\n",
    "dates = ['date']\n",
    "df = pd.read_csv(DATA_DIR + \"/\" + cp['config']['DS']['SRC'],\n",
    "                 usecols=cols,\n",
    "                 parse_dates=dates)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"Italy\"\n",
    "pop_fct = df.loc[df.location==c, 'population'].iloc[0] / 1000\n",
    "\n",
    "IP_SEQ_LEN = cp['config']['DS']['IP_SEQ_LEN']\n",
    "OP_SEQ_LEN = cp['config']['DS']['OP_SEQ_LEN']\n",
    "\n",
    "all_preds = []\n",
    "pred_vals = []\n",
    "out_vals = []\n",
    "\n",
    "test_data = np.array(df.loc[(df.location==c) & (df.total_cases>=100), 'new_cases'].rolling(7, center=True, min_periods=1).mean() / pop_fct, dtype=np.float32)\n",
    "\n",
    "for i in range(len(test_data) - IP_SEQ_LEN - OP_SEQ_LEN + 1):\n",
    "    ip = torch.tensor(test_data[i : i+IP_SEQ_LEN])\n",
    "    op = torch.tensor(test_data[i+IP_SEQ_LEN : i+IP_SEQ_LEN+OP_SEQ_LEN])\n",
    "    ip = ip.to(DEVICE)\n",
    "    op = op.to(DEVICE)\n",
    "\n",
    "    pred = model.predict(ip.view(1, IP_SEQ_LEN, 1))    \n",
    "    if i==0: # prepend first input\n",
    "        out_vals.extend(ip.view(IP_SEQ_LEN).cpu().numpy() * pop_fct)\n",
    "        pred_vals.extend([np.NaN] * IP_SEQ_LEN)\n",
    "    all_preds.append(pred.view(OP_SEQ_LEN).cpu().numpy() * pop_fct)\n",
    "    pred_vals.append(pred.view(OP_SEQ_LEN).cpu().numpy()[0] * pop_fct)\n",
    "    out_vals.append(op.view(OP_SEQ_LEN).cpu().numpy()[0] * pop_fct)\n",
    "\n",
    "# last N-1 values\n",
    "out_vals.extend(op.view(OP_SEQ_LEN).cpu().numpy()[1:] * pop_fct)\n",
    "pred_vals.extend(([np.NaN] * OP_SEQ_LEN)[1:]) # pad with NaN\n",
    "\n",
    "cmp_df = pd.DataFrame({\n",
    "    'actual': out_vals,\n",
    "    'predicted0': pred_vals\n",
    "})\n",
    "\n",
    "# set date\n",
    "start_date = df.loc[(df.location==c) & (df.total_cases>=100)]['date'].iloc[0]\n",
    "end_date = start_date + dt.timedelta(days=cmp_df.index[-1])\n",
    "cmp_df['Date'] = pd.Series([start_date + dt.timedelta(days=i) for i in range(len(cmp_df))])\n",
    "\n",
    "# plot noodles\n",
    "ax=None\n",
    "i=IP_SEQ_LEN\n",
    "mape=[]\n",
    "for pred in all_preds:\n",
    "    cmp_df['predicted_cases'] = np.NaN\n",
    "    cmp_df.loc[i:i+OP_SEQ_LEN-1, 'predicted_cases'] = pred\n",
    "    ax = cmp_df.plot(x='Date', y='predicted_cases', ax=ax, legend=False)\n",
    "    ape = 100 * ((cmp_df['actual'] - cmp_df['predicted_cases']).abs() / cmp_df['actual'])\n",
    "    mape.append(ape.mean())\n",
    "    i+=1\n",
    "acc = f\"{100 - sum(mape)/len(mape):0.2f}%\"\n",
    "\n",
    "# plot primary lines\n",
    "ax = cmp_df.plot(\n",
    "    x='Date',\n",
    "    y=['actual', 'predicted0'],\n",
    "    figsize=(20,8),\n",
    "    lw=5,\n",
    "    title=c + ' | Daily predictions | ' + acc,\n",
    "    ax=ax\n",
    ")\n",
    "mn_l = DayLocator()\n",
    "ax.xaxis.set_minor_locator(mn_l)\n",
    "mj_l = AutoDateLocator()\n",
    "mj_f = ConciseDateFormatter(mj_l, show_offset=False)\n",
    "ax.xaxis.set_major_formatter(mj_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
