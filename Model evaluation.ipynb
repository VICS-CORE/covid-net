{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate a given model and compare multiple models. Push selected models to Neptune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import torch\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.dates import DayLocator, AutoDateLocator, ConciseDateFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "ARCHS_DIR = 'archs'\n",
    "DATA_DIR = 'data'\n",
    "EXPERIMENTS_DIR = 'experiments'\n",
    "DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = '0001_test'\n",
    "checkpoint = 'latest-e100.pt'\n",
    "\n",
    "model, cp = utils.load_model(experiment_id, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss and acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = pd.DataFrame({\n",
    "    'trn_loss': cp['trn_losses'],\n",
    "    'val_loss': cp['val_losses']\n",
    "})\n",
    "\n",
    "df_acc = pd.DataFrame({\n",
    "    'trn_acc': cp.get('trn_acc', np.zeros((cp['config']['NUM_EPOCHS']))),\n",
    "    'val_acc': cp.get('val_acc', np.zeros((cp['config']['NUM_EPOCHS'])))\n",
    "})\n",
    "\n",
    "# smoothen\n",
    "df_loss['trn_loss'] = df_loss['trn_loss'].rolling(3, min_periods=1, center=True).mean()\n",
    "df_loss['val_loss'] = df_loss['val_loss'].rolling(3, min_periods=1, center=True).mean()\n",
    "df_acc['trn_acc'] = df_acc['trn_acc'].rolling(3, min_periods=1, center=True).mean()\n",
    "df_acc['val_acc'] = df_acc['val_acc'].rolling(3, min_periods=1, center=True).mean()\n",
    "\n",
    "_ = df_loss.plot(\n",
    "    y=['trn_loss', 'val_loss'],\n",
    "    title='Loss per epoch',\n",
    "    subplots=False,\n",
    "    figsize=(5,5),\n",
    "    sharex=False,\n",
    "    logy=True\n",
    ")\n",
    "_ = df_acc.plot(\n",
    "    y=['trn_acc', 'val_acc'],\n",
    "    title='Acc per epoch',\n",
    "    subplots=False,\n",
    "    figsize=(5,5),\n",
    "    sharex=False,\n",
    "    logy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['location', 'date', 'total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'population']\n",
    "dates = ['date']\n",
    "df = pd.read_csv(DATA_DIR + \"/\" + cp['config']['DS']['SRC'],\n",
    "                 usecols=cols,\n",
    "                 parse_dates=dates)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(model, country='India', plot=True):\n",
    "    c = country\n",
    "    pop_fct = df.loc[df.location==c, 'population'].iloc[0] / 1000\n",
    "\n",
    "    IP_SEQ_LEN = cp['config']['DS']['IP_SEQ_LEN']\n",
    "    OP_SEQ_LEN = cp['config']['DS']['OP_SEQ_LEN']\n",
    "\n",
    "    all_preds = []\n",
    "    pred_vals = []\n",
    "    real_vals = []\n",
    "\n",
    "    test_data = np.array(df.loc[(df.location==c) & (df.total_cases>=100), cp['config']['DS']['FEATURES']].rolling(7, center=True, min_periods=1).mean() / pop_fct, dtype=np.float32)\n",
    "\n",
    "    ip_shp = IP_SEQ_LEN, len(cp['config']['IP_FEATURES'])\n",
    "    op_shp = OP_SEQ_LEN, len(cp['config']['OP_FEATURES'])\n",
    "\n",
    "    for i in range(len(test_data) - IP_SEQ_LEN - OP_SEQ_LEN + 1):\n",
    "        ip = torch.tensor(test_data[i : i+IP_SEQ_LEN, cp['config']['IP_FEATURES']])\n",
    "        op = torch.tensor(test_data[i+IP_SEQ_LEN : i+IP_SEQ_LEN+OP_SEQ_LEN, cp['config']['OP_FEATURES']])\n",
    "        ip = ip.to(DEVICE)\n",
    "        op = op.to(DEVICE)\n",
    "\n",
    "        pred = model.predict(ip.view(1, IP_SEQ_LEN, len(cp['config']['IP_FEATURES'])))    \n",
    "\n",
    "        all_preds.append(pred.view(op_shp).cpu().numpy() * pop_fct)\n",
    "        pred_vals.append(pred.view(op_shp).cpu().numpy()[0] * pop_fct)\n",
    "        real_vals.append(op.view(op_shp).cpu().numpy()[0] * pop_fct)\n",
    "\n",
    "    # prepend first input\n",
    "    nans = np.ndarray((IP_SEQ_LEN, len(cp['config']['OP_FEATURES'])))\n",
    "    nans.fill(np.NaN)\n",
    "    pred_vals = list(nans) + pred_vals\n",
    "    real_vals = list(test_data[:IP_SEQ_LEN, cp['config']['OP_FEATURES']] * pop_fct) + real_vals\n",
    "    # append last N-1 values\n",
    "    nans = np.ndarray(op_shp)\n",
    "    nans.fill(np.NaN)\n",
    "    pred_vals.extend(nans[1:]) # pad with NaN\n",
    "    real_vals.extend(op.view(op_shp).cpu().numpy()[1:] * pop_fct)\n",
    "\n",
    "    real_vals = np.array(real_vals).reshape(len(test_data), len(cp['config']['OP_FEATURES']))\n",
    "    pred_vals = np.array(pred_vals).reshape(len(test_data), len(cp['config']['OP_FEATURES']))\n",
    "\n",
    "    accs = []\n",
    "    for o in range(len(cp['config']['OP_FEATURES'])):\n",
    "        cmp_df = pd.DataFrame({\n",
    "            'actual': real_vals[:, o],\n",
    "            'predicted0': pred_vals[:, o]\n",
    "        })\n",
    "        # set date\n",
    "        start_date = df.loc[(df.location==c) & (df.total_cases>=100)]['date'].iloc[0]\n",
    "        end_date = start_date + dt.timedelta(days=cmp_df.index[-1])\n",
    "        cmp_df['Date'] = pd.Series([start_date + dt.timedelta(days=i) for i in range(len(cmp_df))])\n",
    "\n",
    "        # plot noodles\n",
    "        ax=None\n",
    "        i=IP_SEQ_LEN\n",
    "        mape=[]\n",
    "        for pred in all_preds:\n",
    "            cmp_df['predicted_cases'] = np.NaN\n",
    "            cmp_df.loc[i:i+OP_SEQ_LEN-1, 'predicted_cases'] = pred[:, o]\n",
    "            ape = 100 * ((cmp_df['actual'] - cmp_df['predicted_cases']).abs() / cmp_df['actual'])\n",
    "            mape.append(ape.mean())\n",
    "            if plot: ax = cmp_df.plot(x='Date', y='predicted_cases', ax=ax, legend=False)\n",
    "            i+=1\n",
    "        acc = 100 - sum(mape)/len(mape)\n",
    "        accs.append(acc)\n",
    "        acc_str = f\"{acc:0.2f}%\"\n",
    "\n",
    "        # plot primary lines\n",
    "        if plot:\n",
    "            ax = cmp_df.plot(\n",
    "                x='Date',\n",
    "                y=['actual', 'predicted0'],\n",
    "                figsize=(20,8),\n",
    "                lw=5,\n",
    "                title=c + ' | Daily predictions | ' + acc_str,\n",
    "                ax=ax\n",
    "            )\n",
    "            mn_l = DayLocator()\n",
    "            ax.xaxis.set_minor_locator(mn_l)\n",
    "            mj_l = AutoDateLocator()\n",
    "            mj_f = ConciseDateFormatter(mj_l, show_offset=False)\n",
    "            ax.xaxis.set_major_formatter(mj_f)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest all models in experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "for e in range(0, 101, 100): # start, stop, step\n",
    "    checkpoint = 'latest-e' + str(e) + '.pt'\n",
    "    try:\n",
    "        model, cp = utils.load_model(experiment_id, checkpoint, v=False)\n",
    "        acc = backtest(model, plot=False)\n",
    "        accs.append(acc)\n",
    "        print(checkpoint, acc)\n",
    "    except Exception as e:\n",
    "        print(checkpoint, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 0 # which output feature's acc should be plotted\n",
    "\n",
    "df_exp = pd.DataFrame({\n",
    "    'acc': np.array(accs)[:, feature],\n",
    "    'epochs': np.arange(0, 101, 100)\n",
    "})\n",
    "_ = df_exp[1:].plot(\n",
    "    x='epochs',\n",
    "    y=['acc'],\n",
    "    title='Test accuracy',\n",
    "    subplots=False,\n",
    "    figsize=(5,5),\n",
    "    sharex=False\n",
    ")\n",
    "\n",
    "print(\"Models with best test accuracy:\")\n",
    "print(df_exp.sort_values('acc', ascending=False).head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
