{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from OWID and generate dataset files with train-val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import torch\n",
    "from torch.utils import data as tdt\n",
    "\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://covid.ourworldindata.org/data/owid-covid-data.csv --output data/owid_$(date +%Y-%m-%d).csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'FEATURES': ['new_cases', 'new_deaths'],\n",
    "    \"VAL_RATIO\": 0.3,\n",
    "    \"IP_SEQ_LEN\": 40,\n",
    "    \"OP_SEQ_LEN\": 20,\n",
    "    \"SRC\": \"owid_2020-06-24.csv\"\n",
    "}\n",
    "fn = \"ds_cd_\" + str(config['IP_SEQ_LEN']) + str(config['OP_SEQ_LEN']) + '_' + config['SRC'] + \".pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['location', 'date', 'total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'population']\n",
    "dates = ['date']\n",
    "df = pd.read_csv(DATA_DIR + \"/\" + config['SRC'],\n",
    "                 usecols=cols,\n",
    "                 parse_dates=dates)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(cfg):\n",
    "    IP_SEQ_LEN = cfg['IP_SEQ_LEN']\n",
    "    OP_SEQ_LEN = cfg['OP_SEQ_LEN']\n",
    "    VAL_RATIO = cfg['VAL_RATIO']\n",
    "    \n",
    "    ip_trn = []\n",
    "    op_trn = []\n",
    "\n",
    "    countries = df['location'].unique()\n",
    "    pop_countries = ['China', 'United States', 'Indonesia', 'Pakistan', 'Brazil', 'Bangladesh', 'Russia', 'Mexico']\n",
    "\n",
    "    c = 0\n",
    "    for country in countries:\n",
    "        if country in ['World', 'International', 'India']: # Countries to be skipped\n",
    "            continue\n",
    "        country_df = df.loc[df.location == country]\n",
    "        tot_cases_gt_100 = (country_df['total_cases'] >= 100)\n",
    "        country_df = country_df.loc[tot_cases_gt_100]\n",
    "\n",
    "        if len(country_df) >= IP_SEQ_LEN + OP_SEQ_LEN:\n",
    "            c += 1\n",
    "            pop = country_df['population'].iloc[0]\n",
    "            print(c, country, len(country_df), pop)\n",
    "            daily_cases = np.array(country_df[cfg['FEATURES']].rolling(7, center=True, min_periods=1).mean() * 1000 / pop, dtype=np.float32)\n",
    "\n",
    "            for i in range(len(country_df) - IP_SEQ_LEN - OP_SEQ_LEN + 1):\n",
    "                ip_trn.append(daily_cases[i : i+IP_SEQ_LEN])\n",
    "                op_trn.append(daily_cases[i+IP_SEQ_LEN : i+IP_SEQ_LEN+OP_SEQ_LEN])\n",
    "\n",
    "    ip_trn = torch.from_numpy(np.array(ip_trn, dtype=np.float32))\n",
    "    op_trn = torch.from_numpy(np.array(op_trn, dtype=np.float32))\n",
    "    dataset = tdt.TensorDataset(ip_trn, op_trn)\n",
    "\n",
    "    val_len = int(VAL_RATIO * len(dataset))\n",
    "    trn_len = len(dataset) - val_len\n",
    "    trn_set, val_set = tdt.random_split(dataset, (trn_len, val_len))\n",
    "    return trn_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ds = torch.load(DATA_DIR + '/' + fn)\n",
    "    trn_set, val_set, ds_cfg = ds['trn'], ds['val'], ds['config']\n",
    "    print(fn, \"already exists.\")\n",
    "    print(ds_cfg)\n",
    "except FileNotFoundError:\n",
    "    trn_set, val_set = gen_dataset(config)\n",
    "    torch.save({'trn': trn_set, 'val': val_set, 'config': config}, DATA_DIR + '/' + fn)\n",
    "    print(\"Saved dataset to\", fn)\n",
    "finally:\n",
    "    print(\"Training data:\", len(trn_set), \"Validation data:\", len(val_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
